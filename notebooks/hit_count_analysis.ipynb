{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HITS Count Data Analysis\n",
    "\n",
    "Analysis on general dataset characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: done reading in dataset to pandas dataframes in 164.987s.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "import re\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# hits = pd.read_json('datasets/20200126-20200312-hits.json', lines=True)\n",
    "\n",
    "\n",
    "d_1 = pd.read_json('../mturk/20200126-20200202/hits.json', lines=True)\n",
    "\n",
    "d_2 = pd.read_json('../mturk/20200217-20200227/hits.json', lines=True)\n",
    "\n",
    "d_3 = pd.read_json('../mturk/20200227-20200303/hits.json', lines=True)\n",
    "\n",
    "d_4 = pd.read_json('../mturk/20200303-20200312/hits.json', lines=True)\n",
    "\n",
    "\n",
    "d_1['description'] = d_1['description'].map(lambda d : re.sub('[,.$()@#%&~!?]', ' ', d))\n",
    "d_2['description'] = d_2['description'].map(lambda d : re.sub('[,.$()@#%&~!?]', ' ', d))\n",
    "d_3['description'] = d_3['description'].map(lambda d : re.sub('[,.$()@#%&~!?]', ' ', d))\n",
    "d_4['description'] = d_4['description'].map(lambda d : re.sub('[,.$()@#%&~!?]', ' ', d))\n",
    "\n",
    "\n",
    "d_1['title'] = d_1['title'].map(lambda d : re.sub('[,.$()@#%&~!?]', ' ', d))\n",
    "d_2['title'] = d_2['title'].map(lambda d : re.sub('[,.$()@#%&~!?]', ' ', d))\n",
    "d_3['title'] = d_3['title'].map(lambda d : re.sub('[,.$()@#%&~!?]', ' ', d))\n",
    "d_4['title'] = d_4['title'].map(lambda d : re.sub('[,.$()@#%&~!?]', ' ', d))\n",
    "\n",
    "\n",
    "\n",
    "print('INFO: done reading in dataset to pandas dataframes in %0.3fs.' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1 = pd.read_csv('datasets/time_preview_1.txt', names=['previews'], delim_whitespace=True)\n",
    "p_2 = pd.read_csv('datasets/time_preview_2.txt', names=['previews'], delim_whitespace=True)\n",
    "p_3 = pd.read_csv('datasets/time_preview_3.txt', names=['previews'], delim_whitespace=True)\n",
    "p_4 = pd.read_csv('datasets/time_preview_4.txt', names=['previews'], delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39009, 1)\n",
      "                                                previews\n",
      "0      mechanical turk preview       about           ...\n",
      "1                                                    NaN\n",
      "2          tell us what this item is - electronics - ...\n",
      "3            aidea - mturk         review the summary...\n",
      "4      mechanical turk preview       about           ...\n",
      "...                                                  ...\n",
      "39004  hit                                           ...\n",
      "39005  hit                                           ...\n",
      "39006    m turk question                       extrac...\n",
      "39007      do these profile photos contain a real hum...\n",
      "39008  hit       audit receipt transcription hit for ...\n",
      "\n",
      "[39009 rows x 1 columns]\n",
      "0             Input specific values displayed in the image \n",
      "1         Write question-answer pairs about verbal nouns...\n",
      "2                             Data Entry from images  P641 \n",
      "3         Extract purchased items from a shopping receip...\n",
      "4                      Verify a single value from a receipt\n",
      "                                ...                        \n",
      "231016                         Are these receipts the same \n",
      "231017    Full Text Review - Earn up to  0 17 per media ...\n",
      "231018                                      Transcribe data\n",
      "231019              Select the option that you would prefer\n",
      "231020                                     Classify Receipt\n",
      "Name: title, Length: 231021, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(p_1.shape)\n",
    "print(p_1)\n",
    "print(d_1['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  1\n",
      "INFO: done parsing preview dataset, finished in 1100.295s.\n",
      "INFO: total previews:  46521  Previews with page src:  39009  Preview w/o page src:  7512\n",
      "processing  2\n",
      "INFO: done parsing preview dataset, finished in 3322.387s.\n",
      "INFO: total previews:  60605  Previews with page src:  54466  Preview w/o page src:  6139\n",
      "processing  3\n",
      "INFO: done parsing preview dataset, finished in 2847.914s.\n",
      "INFO: total previews:  55210  Previews with page src:  50481  Preview w/o page src:  4729\n",
      "processing  4\n",
      "INFO: done parsing preview dataset, finished in 2489.724s.\n",
      "INFO: total previews:  72416  Previews with page src:  62950  Preview w/o page src:  9466\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from time import time\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import re\n",
    "# from pprint import pprint\n",
    "\n",
    "# from getpass import getpass\n",
    "# from html import unescape\n",
    "\n",
    "# import json\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# def process_preview(preview_file, out_num):\n",
    "#     print('processing ', out_num)\n",
    "#     preview_src_cnt = 0\n",
    "#     preview_no_src_cnt = 0\n",
    "#     previews = []\n",
    "\n",
    "#     t0 = time()\n",
    "#     for line in open(preview_file):\n",
    "#           preview = json.loads(line)\n",
    "\n",
    "#           if 'page_src' in preview:\n",
    "#             preview_src_cnt += 1\n",
    "#             page_src = preview['page_src']\n",
    "#             soup = BeautifulSoup(page_src, 'html.parser')\n",
    "#             # print(soup.find_all('script'))\n",
    "\n",
    "#             # Clear every script tag\n",
    "#             for tag in soup.find_all('script'):\n",
    "#                 tag.clear()\n",
    "\n",
    "#             # Clear every style tag\n",
    "#             for tag in soup.find_all('style'):\n",
    "#                 tag.clear()\n",
    "\n",
    "#             # print(soup.get_text())\n",
    "#             clean_src = re.sub(\"<.*?>\", \"\", soup.get_text())\n",
    "#             clean_src = re.sub(\"\\n\", \" \", clean_src)\n",
    "#             previews.append(clean_src)\n",
    "#           else:\n",
    "#             preview_no_src_cnt += 1\n",
    "\n",
    "#     print('INFO: done parsing preview dataset, finished in %0.3fs.' % (time() - t0))\n",
    "#     print('INFO: total previews: ', (preview_src_cnt + preview_no_src_cnt), ' Previews with page src: ', preview_src_cnt, ' Preview w/o page src: ', preview_no_src_cnt)\n",
    "\n",
    "\n",
    "#     preview_df = pd.DataFrame(previews, columns=['processed_previews'])\n",
    "#     preview_df.head()\n",
    "\n",
    "#     preview_df['processed_previews'] = preview_df['processed_previews'].map(lambda d : re.sub('[,.$()@#%&~!?]', '', d))\n",
    "\n",
    "#     preview_df['processed_previews'] = preview_df['processed_previews'].map(lambda d : d.lower())\n",
    "    \n",
    "#     dat_out = 'datasets/time_preview_' + str(out_num) + '.txt'\n",
    "#     preview_df['processed_previews'].to_csv(dat_out, header=None, index=None, sep=' ', mode='a')\n",
    "#     return preview_df\n",
    "\n",
    "\n",
    "# p_1 = process_preview('../mturk/20200126-20200202/preview.json', 1)\n",
    "\n",
    "# p_2 = process_preview('../mturk/20200217-20200227/preview.json', 2)\n",
    "\n",
    "# p_3 = process_preview('../mturk/20200227-20200303/preview.json', 3)\n",
    "\n",
    "# p_4 = process_preview('../mturk/20200303-20200312/preview.json', 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(d_1.description.value_counts())\n",
    "# d1_desc = d_1.description.str.lower().str.split()\n",
    "# print(d1_desc)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# print(d_1.description.str.lower().str.split())\n",
    "# print(d_1.description.str.lower().str.split(' '))\n",
    "\n",
    "desc_1 = Counter(\" \".join(d_1.description.str.lower()).split(\" \"))\n",
    "desc_2 = Counter(\" \".join(d_2.description.str.lower()).split(\" \"))\n",
    "desc_3 = Counter(\" \".join(d_3.description.str.lower()).split(\" \"))\n",
    "desc_4 = Counter(\" \".join(d_4.description.str.lower()).split(\" \"))\n",
    "\n",
    "tit_1 = Counter(\" \".join(d_1.title.str.lower()).split(\" \"))\n",
    "tit_2 = Counter(\" \".join(d_2.title.str.lower()).split(\" \"))\n",
    "tit_3 = Counter(\" \".join(d_3.title.str.lower()).split(\" \"))\n",
    "tit_4 = Counter(\" \".join(d_4.title.str.lower()).split(\" \"))\n",
    "\n",
    "# print(d_1.description)\n",
    "print(p_1.previews.tolist())\n",
    "# pre_1 = Counter(\" \".join(p_1.previews.str.lower()).split(\" \"))\n",
    "# pre_2 = Counter(\" \".join(p_2.previews.str.lower()).split(\" \"))\n",
    "# pre_3 = Counter(\" \".join(p_3.previews.str.lower()).split(\" \"))\n",
    "# pre_4 = Counter(\" \".join(p_4.previews.str.lower()).split(\" \"))\n",
    "\n",
    "\n",
    "# print(d_1.description.count())\n",
    "# counts = Counter(d_1)\n",
    "\n",
    "# print(counter_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-001a8d0ce61f>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-001a8d0ce61f>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for word in key_words\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def count_words(key_words):\n",
    "    set_1 = 0\n",
    "    set_2 = 1\n",
    "    set\n",
    "    for word in key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "6\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "key_words = 'primary'\n",
    "\n",
    "print(desc_1[key_words])\n",
    "print(desc_2[key_words])\n",
    "print(desc_3[key_words])\n",
    "print(desc_4[key_words])\n",
    "# print(desc_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "5\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print(tit_1[key_words])\n",
    "print(tit_2[key_words])\n",
    "print(tit_3[key_words])\n",
    "print(tit_4[key_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d8648888b361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pre_1' is not defined"
     ]
    }
   ],
   "source": [
    "print(pre_1[key_words])\n",
    "print(pre_2[key_words])\n",
    "print(pre_3[key_words])\n",
    "print(pre_4[key_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('INFO: sorting hits by creation time')\n",
    "hits = hits.sort_values('hit_set_id')\n",
    "\n",
    "print('INFO: finished sorting hits by creation time in %.3fs' % (time() - t0))\n",
    "hits.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('INFO: shape of HITS df before drop dup: {}'.format(hits.shape))\n",
    "# hits = hits.drop_duplicates(subset=['hit_set_id', 'creation_time'], keep='first')\n",
    "print('INFO: shape of HITS df after drop dup: {}'.format(hits.shape))\n",
    "\n",
    "hits.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique requester in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['requester_id'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Requester's by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['requester_name'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Requesters by HITs issued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['requester_name'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['requester_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total number of hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hits.shape[0])\n",
    "requester_hits = hits['requester_name'].value_counts().tolist()\n",
    "# print(requester_hits)\n",
    "print('total num_hits: ', sum(requester_hits))\n",
    "\n",
    "# print(requester_hits_name)\n",
    "# requester_hits.plot.pie(y='requester_name', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of hits from top 10 requesters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_count = sum(requester_hits[:10])\n",
    "\n",
    "print('top_ten_count:', top_ten_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of hits from the rest of the requesters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rest of requesters: ', sum(requester_hits[10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PiChart of top 10 requesters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_requesters = hits['requester_name'].value_counts().index.tolist()\n",
    "top_requesters = top_requesters[:10]\n",
    "\n",
    "top_requesters.append('Rest of Requesters')\n",
    "\n",
    "top_req_hit_cnt = hits['requester_name'].value_counts().tolist()\n",
    "top_req_hit_cnt = top_req_hit_cnt[:10]\n",
    "\n",
    "rest_req_hit_cnt = sum(requester_hits[10:])\n",
    "print(top_requesters)\n",
    "\n",
    "top_req_hit_cnt.append(rest_req_hit_cnt)\n",
    "\n",
    "print(top_req_hit_cnt)\n",
    "\n",
    "print(len(top_req_hit_cnt))\n",
    "\n",
    "\n",
    "requester_label = [ 'Requester #1', 'Requester #2','Requester #3','Requester #4','Requester #5','Requester #6','Requester #7',\n",
    "                  'Requester #8','Requester #9', 'Requester #10', 'Rest of Requesters'\n",
    "                  ]\n",
    "\n",
    "colors = ['#FF772B', '#E658E8', '#6E91FF', '#58E8A7', '#EFFF61', \n",
    "          '#CF3CFF', '#3198E8', '#42FF52', '#EBD25B', '#FF6236', \n",
    "          '#77334a'\n",
    "         ]\n",
    "print(len(requester_label))\n",
    "\n",
    "print(requester_label)\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(14, 14))\n",
    "\n",
    "ax1.pie(top_req_hit_cnt, labels=requester_label, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "plt.rcParams['font.size'] = 14.0\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.savefig('results_figures/hit_analysis/top10-pi.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "money = pd.json_normalize(hits['monetary_reward'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approval = pd.json_normalize(hits['requesterInfo'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# money.drop(columns=['$numberDouble', '$numberInt'], axis=1)\n",
    "# money.head()\n",
    "money.axes\n",
    "# money.drop(columns=['amount_in_dollars.$numberInt'])\n",
    "\n",
    "\n",
    "flat_hits = pd.concat([hits,money, approval], axis=1, sort=False)\n",
    "\n",
    "flat_hits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
