{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lda2vec setup in jupyter notebook\n",
    "\n",
    "### Install all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/Users/rileymiller/Library/Caches/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: pyLDAvis in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (2.1.2)\n",
      "Requirement already satisfied: numexpr in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (2.7.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (0.34.2)\n",
      "Requirement already satisfied: future in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (1.4.1)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (5.4.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (2.11.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (0.21.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (0.14.1)\n",
      "Requirement already satisfied: funcy in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (1.14)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pyLDAvis) (1.18.1)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.13.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.5.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pytest->pyLDAvis) (8.2.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pytest->pyLDAvis) (19.3.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.1.8)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pytest->pyLDAvis) (20.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2019.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from packaging->pytest->pyLDAvis) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/envs/lda2vec/lib/python3.6/site-packages (from packaging->pytest->pyLDAvis) (2.4.6)\n",
      "\u001b[33mWARNING: The directory '/Users/rileymiller/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/Users/rileymiller/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.12.21)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.21 in /usr/local/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.15.21)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.21->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.21->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "\u001b[33mWARNING: The directory '/Users/rileymiller/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/Users/rileymiller/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "\u001b[33mWARNING: The directory '/Users/rileymiller/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/Users/rileymiller/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from nltk) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/usr/local/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: done importing libraries and dataset in 0.000s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rileymiller/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis\n",
    "!pip3 install gensim\n",
    "!pip3 install matplotlib\n",
    "!pip3 install nltk\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "print('INFO: done importing libraries and dataset in %0.3fs.' % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: done reading in dataset to pandas dataframe in 18.935s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "hits = pd.read_json('datasets/clean_hits_full_week.json', lines=True)\n",
    "hits.head()\n",
    "\n",
    "print('INFO: done reading in dataset to pandas dataframe in %0.3fs.' % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: done columns from dataframe in 1.353s.\n",
      "INFO: done removing punctuation from title and description in 0.988s.\n",
      "INFO: done converting text to lowercase in 0.263s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    you will be presented an image of a gym cardio...\n",
       "1    given a sentence and a noun from that sentence...\n",
       "2                         transcribing data from image\n",
       "3    extract all the items from the receipt you wil...\n",
       "4    verify the value of single data point (such as...\n",
       "Name: processed_description, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "hits = hits.drop(columns=['_id', 'hit_set_id', 'requester_id','requester_name', 'assignment_duration_in_seconds', 'creation_time', 'assignable_hits_count', 'latest_expiration_time', 'caller_meets_requirements', 'caller_meets_preview_requirements', 'last_updated_time', 'monetary_reward', 'accept_project_task_url', 'requester_url', 'project_tasks_url', 'project_requirements', 'requesterInfo'], axis=1)\n",
    "hits.head()\n",
    "\n",
    "print('INFO: done columns from dataframe in %0.3fs.' % (time() - t0))\n",
    "\n",
    "# removes all punctuation from the description and title if any\n",
    "t0 = time()\n",
    "\n",
    "hits['processed_description'] = hits['description'].map(lambda d : re.sub('[,.!?]', '', d))\n",
    "hits['processed_title'] = hits['title'].map(lambda t : re.sub('[,.!?]', '', t))\n",
    "\n",
    "print('INFO: done removing punctuation from title and description in %0.3fs.' % (time() - t0))\n",
    "\n",
    "\n",
    "# converts the text to lowercase\n",
    "t0 = time()\n",
    "\n",
    "hits['processed_description'] = hits['processed_description'].map(lambda x: x.lower())\n",
    "hits['processed_title'] = hits['processed_title'].map(lambda x: x.lower())\n",
    "\n",
    "print('INFO: done converting text to lowercase in %0.3fs.' % (time() - t0))\n",
    "\n",
    "\n",
    "# print out the first couple processed descriptions\n",
    "hits['processed_description'].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: beginning preprocesssing tokens from descriptions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Tokenizing Texts ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231021it [00:07, 31654.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 3210 low frequency tokens out of 4448 total tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 189.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Getting Skipgrams ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231021it [01:14, 3100.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: finished preprocessing tokens from descriptions in 116.227s.\n",
      "INFO: loading glove embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: finished loading glove embeddings in 170.137s.\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install lda2vec\n",
    "from lda2vec.nlppipe import Preprocessor\n",
    "# Where to save preprocessed data\n",
    "clean_data_dir = \"data/clean_data\"\n",
    "# Name of input file. Should be inside of data_dir\n",
    "# input_file = \"20_newsgroups.txt\"\n",
    "# Should we load pretrained embeddings from file\n",
    "load_embeds = True\n",
    "\n",
    "# Read in data file\n",
    "# df = pd.read_csv(data_dir+\"/\"+input_file, sep=\"\\t\")\n",
    "\n",
    "# Initialize a preprocessor\n",
    "P = Preprocessor(hits, \"processed_description\", max_features=30000, maxlen=10000, min_count=30)\n",
    "\n",
    "# Run the preprocessing on your dataframe\n",
    "t0 = time()\n",
    "    \n",
    "print('INFO: beginning preprocesssing tokens from descriptions')\n",
    "\n",
    "P.preprocess()\n",
    "\n",
    "print('INFO: finished preprocessing tokens from descriptions in %0.3fs.' % (time() - t0))\n",
    "\n",
    "# Load embeddings from file if we choose to do so\n",
    "if load_embeds:\n",
    "    # Load embedding matrix from file path - change path to where you saved them\n",
    "    t0 = time()\n",
    "    \n",
    "    print('INFO: loading glove embeddings')\n",
    "    embedding_matrix = P.load_glove(\"embeddings/glove.42B.300d.txt\")\n",
    "    \n",
    "    print('INFO: finished loading glove embeddings in %0.3fs.' % (time() - t0))\n",
    "else:\n",
    "    embedding_matrix = None\n",
    "\n",
    "# Save data to data_dir\n",
    "P.save_data(clean_data_dir, embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "INFO: loading preprocessed data\n",
      "INFO: finished loading preprocessed data in 9.305s.\n",
      "INFO: initializing lda2vec model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:40: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:42: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:69: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/word_embedding.py:18: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/embedding_mixture.py:25: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:140: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:162: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:177: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:183: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:183: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:186: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:85: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "INFO: finished initializing lda2vec model in 1.889s.\n",
      "INFO: training lda2vec\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:216: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:227: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/lda2vec/Lda2vec.py:229: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "\n",
      "EPOCH: 1\n"
     ]
    }
   ],
   "source": [
    "from lda2vec import utils, model\n",
    "\n",
    "print(tf.__version__)\n",
    "# Path to preprocessed data\n",
    "clean_data_dir = \"data/clean_data\"\n",
    "# Whether or not to load saved embeddings file\n",
    "load_embeds = True\n",
    "\n",
    "# Load data from files\n",
    "t0 = time()\n",
    "\n",
    "print('INFO: loading preprocessed data')\n",
    "(idx_to_word, word_to_idx, freqs, pivot_ids,\n",
    " target_ids, doc_ids, embed_matrix) = utils.load_preprocessed_data(clean_data_dir, load_embed_matrix=load_embeds)\n",
    "\n",
    "print('INFO: finished loading preprocessed data in %0.3fs.' % (time() - t0))\n",
    "\n",
    "# Number of unique documents\n",
    "num_docs = doc_ids.max() + 1\n",
    "# Number of unique words in vocabulary (int)\n",
    "vocab_size = len(freqs) + 500\n",
    "# Embed layer dimension size\n",
    "# If not loading embeds, change 128 to whatever size you want.\n",
    "embed_size = embed_matrix.shape[1] if load_embeds else 128\n",
    "# Number of topics to cluster into\n",
    "num_topics = 9\n",
    "# Amount of iterations over entire dataset\n",
    "num_epochs = 200\n",
    "# Batch size - Increase/decrease depending on memory usage\n",
    "batch_size = 4096\n",
    "# Epoch that we want to \"switch on\" LDA loss\n",
    "switch_loss_epoch = 0\n",
    "# Pretrained embeddings value\n",
    "pretrained_embeddings = embed_matrix if load_embeds else None\n",
    "# If True, save logdir, otherwise don't\n",
    "save_graph = True\n",
    "\n",
    "# Initialize the model\n",
    "t0 = time()\n",
    "\n",
    "print('INFO: initializing lda2vec model')\n",
    "m = model(num_docs,\n",
    "          vocab_size,\n",
    "          num_topics,\n",
    "          embedding_size=embed_size,\n",
    "          pretrained_embeddings=pretrained_embeddings,\n",
    "          freqs=freqs,\n",
    "          batch_size = batch_size,\n",
    "          save_graph_def=save_graph)\n",
    "\n",
    "print('INFO: finished initializing lda2vec model in %0.3fs.' % (time() - t0))\n",
    "\n",
    "\n",
    "# Train the model\n",
    "t0 = time()\n",
    "\n",
    "print('INFO: training lda2vec')\n",
    "m.train(pivot_ids,\n",
    "        target_ids,\n",
    "        doc_ids,\n",
    "        len(pivot_ids),\n",
    "        num_epochs,\n",
    "        idx_to_word=idx_to_word,\n",
    "        switch_loss_epoch=switch_loss_epoch)\n",
    "\n",
    "print('INFO: finished training lda2vec model in %0.3fs.' % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
